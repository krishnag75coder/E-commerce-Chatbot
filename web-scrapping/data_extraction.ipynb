{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T09:43:48.818245Z",
     "start_time": "2026-02-21T09:43:48.810701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import lxml\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.keys import Keys"
   ],
   "id": "36811c6fbf3d749",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T09:48:55.445185Z",
     "start_time": "2026-02-21T09:43:50.630519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "search_box_text = \"sports shoes for women\"\n",
    "website_link = \"https://www.flipkart.com/\"\n",
    "\n",
    "session_start_time = datetime.now().time()\n",
    "print(f\"Session Start Time: {session_start_time} -------------------------->\")\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(website_link)\n",
    "driver.maximize_window()\n",
    "wait = WebDriverWait(driver, 30)\n",
    "\n",
    "# ---------- Close login popup if present ----------\n",
    "try:\n",
    "    close_btn = wait.until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \"button._2KpZ6l._2doB4z\"))\n",
    "    )\n",
    "    close_btn.click()\n",
    "    print(\"Popup closed\")\n",
    "except:\n",
    "    print(\"No popup appeared\")\n",
    "\n",
    "# ---------- Search ----------\n",
    "print(\"Waiting for search box...\")\n",
    "search_input = wait.until(\n",
    "    EC.presence_of_element_located((By.NAME, \"q\"))\n",
    ")\n",
    "\n",
    "print(\"Typing search query...\")\n",
    "search_input.send_keys(search_box_text)\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "# ---------- Wait for results ----------\n",
    "wait.until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href*=\"/p/\"]'))\n",
    ")\n",
    "\n",
    "print(\"Collecting product links...\")\n",
    "\n",
    "all_product_links = []\n",
    "\n",
    "while True:\n",
    "    time.sleep(2)\n",
    "\n",
    "    products = driver.find_elements(By.CSS_SELECTOR, 'a[href*=\"/p/\"]')\n",
    "    links = [p.get_attribute(\"href\") for p in products if p.get_attribute(\"href\")]\n",
    "    all_product_links.extend(links)\n",
    "\n",
    "    print(f\"Collected {len(all_product_links)} links so far\")\n",
    "\n",
    "    # ---------- Try clicking Next ----------\n",
    "    try:\n",
    "        next_btn = driver.find_element(By.XPATH, '//a/span[text()=\"Next\"]/..')\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", next_btn)\n",
    "        time.sleep(1)\n",
    "\n",
    "        driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "\n",
    "        wait.until(\n",
    "            EC.staleness_of(products[0])\n",
    "        )\n",
    "\n",
    "    except:\n",
    "        print(\"No more pages\")\n",
    "        break\n",
    "\n",
    "# ---------- Remove duplicates ----------\n",
    "all_product_links = list(set(all_product_links))\n",
    "\n",
    "print(\"Total Unique Product Links:\", len(all_product_links))\n",
    "\n",
    "# ---------- Save CSV ----------\n",
    "df = pd.DataFrame(all_product_links, columns=[\"product_links\"])\n",
    "df.to_csv(\"flipkart_product_links.csv\", index=False)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "session_end_time = datetime.now().time()\n",
    "print(f\"Session End Time: {session_end_time} -------------------------->\")"
   ],
   "id": "d644b9f71f1ec3c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Start Time: 15:13:50.639314 -------------------------->\n",
      "No popup appeared\n",
      "Waiting for search box...\n",
      "Typing search query...\n",
      "Collecting product links...\n",
      "Collected 125 links so far\n",
      "Collected 250 links so far\n",
      "Collected 375 links so far\n",
      "Collected 500 links so far\n",
      "Collected 625 links so far\n",
      "Collected 750 links so far\n",
      "Collected 875 links so far\n",
      "Collected 1000 links so far\n",
      "Collected 1125 links so far\n",
      "Collected 1250 links so far\n",
      "Collected 1375 links so far\n",
      "Collected 1500 links so far\n",
      "Collected 1625 links so far\n",
      "Collected 1750 links so far\n",
      "Collected 1875 links so far\n",
      "Collected 2000 links so far\n",
      "Collected 2125 links so far\n",
      "Collected 2250 links so far\n",
      "Collected 2375 links so far\n",
      "Collected 2500 links so far\n",
      "Collected 2625 links so far\n",
      "Collected 2750 links so far\n",
      "Collected 2875 links so far\n",
      "Collected 3000 links so far\n",
      "Collected 3125 links so far\n",
      "Collected 3250 links so far\n",
      "Collected 3375 links so far\n",
      "Collected 3500 links so far\n",
      "Collected 3625 links so far\n",
      "Collected 3750 links so far\n",
      "Collected 3875 links so far\n",
      "Collected 4000 links so far\n",
      "Collected 4125 links so far\n",
      "Collected 4250 links so far\n",
      "Collected 4375 links so far\n",
      "No more pages\n",
      "Total Unique Product Links: 1405\n",
      "Session End Time: 15:18:55.437147 -------------------------->\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T09:51:10.707013Z",
     "start_time": "2026-02-21T09:49:38.223960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "# session start time\n",
    "session_start_time = datetime.now().time()\n",
    "print(f\"Session Start Time: {session_start_time} ---------------------------> \")\n",
    "\n",
    "# read csv of product links\n",
    "df_product_links = pd.read_csv(\"flipkart_product_links.csv\")\n",
    "\n",
    "# remove limit if scraping all\n",
    "df_product_links = df_product_links.head(10)\n",
    "\n",
    "all_product_links = df_product_links['product_links'].tolist()\n",
    "print(\"Collecting Individual Product Detail Information\")\n",
    "\n",
    "# start browser\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 30)\n",
    "\n",
    "complete_product_details = []\n",
    "unavailable_products = []\n",
    "\n",
    "success = 0\n",
    "failed = 0\n",
    "\n",
    "for product_page_link in all_product_links:\n",
    "    try:\n",
    "        driver.get(product_page_link)\n",
    "\n",
    "        # ---------- close popup if appears ----------\n",
    "        try:\n",
    "            close_btn = WebDriverWait(driver,5).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR,'button._2KpZ6l._2doB4z'))\n",
    "            )\n",
    "            close_btn.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # ---------- wait for page ----------\n",
    "        wait.until(lambda d: d.execute_script(\"return document.readyState\") == \"complete\")\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME,\"body\")))\n",
    "\n",
    "        # ---------- check unavailable ----------\n",
    "        try:\n",
    "            status = driver.find_element(By.XPATH,\"//*[contains(text(),'Unavailable') or contains(text(),'Sold Out')]\").text\n",
    "            unavailable_products.append(product_page_link)\n",
    "            print(\"Unavailable:\", product_page_link)\n",
    "            continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # ---------- brand ----------\n",
    "        try:\n",
    "            brand = driver.find_element(By.CSS_SELECTOR,\"span.mEh187\").text\n",
    "        except:\n",
    "            brand = \"\"\n",
    "\n",
    "        # ---------- title ----------\n",
    "        try:\n",
    "            title = driver.find_element(By.CSS_SELECTOR,\"span.VU-ZEz\").text\n",
    "            title = re.sub(r'\\s*\\([^)]*\\)', '', title)\n",
    "        except:\n",
    "            title = \"\"\n",
    "\n",
    "        # ---------- price ----------\n",
    "        try:\n",
    "            price = driver.find_element(By.CSS_SELECTOR,\"div.Nx9bqj\").text\n",
    "            price = int(re.sub(r\"[^\\d]\",\"\",price))\n",
    "        except:\n",
    "            price = \"\"\n",
    "\n",
    "        # ---------- discount ----------\n",
    "        try:\n",
    "            discount = driver.find_element(By.CSS_SELECTOR,\"div.UkUFwK\").text\n",
    "            discount = int(re.sub(r\"[^\\d]\",\"\",discount))\n",
    "        except:\n",
    "            discount = \"\"\n",
    "\n",
    "        # ---------- ratings ----------\n",
    "        try:\n",
    "            avg_rating = driver.find_element(By.CSS_SELECTOR,\"div.XQDdHH\").text\n",
    "        except:\n",
    "            avg_rating = \"\"\n",
    "\n",
    "        try:\n",
    "            total_ratings = driver.find_element(By.CSS_SELECTOR,\"span.Wphh3N\").text\n",
    "            total_ratings = int(re.sub(r\"[^\\d]\",\"\", total_ratings))\n",
    "        except:\n",
    "            total_ratings = \"\"\n",
    "\n",
    "        # ---------- save ----------\n",
    "        complete_product_details.append([\n",
    "            product_page_link,\n",
    "            title,\n",
    "            brand,\n",
    "            price,\n",
    "            discount,\n",
    "            avg_rating,\n",
    "            total_ratings\n",
    "        ])\n",
    "\n",
    "        success += 1\n",
    "        print(f\"Success {success}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        unavailable_products.append(product_page_link)\n",
    "        print(\"Failed:\", product_page_link, e)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# ---------- dataframe ----------\n",
    "df = pd.DataFrame(\n",
    "    complete_product_details,\n",
    "    columns=['product_link','title','brand','price','discount','avg_rating','total_ratings']\n",
    ")\n",
    "\n",
    "# duplicates\n",
    "df_duplicate_products = df[df.duplicated()]\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# unavailable df\n",
    "df_unavailable_products = pd.DataFrame(unavailable_products, columns=['link'])\n",
    "\n",
    "# ---------- stats ----------\n",
    "print(\"Total product pages:\", len(all_product_links))\n",
    "print(\"Final products:\", len(df))\n",
    "print(\"Unavailable:\", len(df_unavailable_products))\n",
    "print(\"Duplicates:\", len(df_duplicate_products))\n",
    "\n",
    "# ---------- save ----------\n",
    "df.to_csv(\"flipkart_product_data.csv\", index=False)\n",
    "df_unavailable_products.to_csv(\"unavailable_products.csv\", index=False)\n",
    "df_duplicate_products.to_csv(\"duplicate_products.csv\", index=False)\n",
    "\n",
    "session_end_time = datetime.now().time()\n",
    "print(f\"Session End Time: {session_end_time} ---------------------------> \")"
   ],
   "id": "b44420b36172cd70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Start Time: 15:19:40.258937 ---------------------------> \n",
      "Collecting Individual Product Detail Information\n",
      "Success 1\n",
      "Success 2\n",
      "Success 3\n",
      "Success 4\n",
      "Success 5\n",
      "Success 6\n",
      "Success 7\n",
      "Success 8\n",
      "Success 9\n",
      "Success 10\n",
      "Total product pages: 10\n",
      "Final products: 10\n",
      "Unavailable: 0\n",
      "Duplicates: 0\n",
      "Session End Time: 15:21:10.693596 ---------------------------> \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7b8bce7e7e55a7a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
